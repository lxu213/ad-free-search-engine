{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Notes, Links, Code Snippets During Common Crawl Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links\n",
    "\n",
    "Example Repo: https://github.com/commoncrawl/cc-pyspark\n",
    "\n",
    "Common Crawl Format Example: https://gist.github.com/Smerity/e750f0ef0ab9aa366558#file-bbc-warc\n",
    "\n",
    "Implementing a Search Engine with Ranking in Python: http://aakashjapi.com/fuckin-search-engines-how-do-they-work/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run extract_keyword.py in shell\n",
    "$ cd data/ad-free-search-engine\n",
    "$ python extract_keyword.py input/test_wat.txt output\n",
    "\n",
    "# activate vertual environment    \n",
    "$ cd data/ad-free-search-engine/\n",
    "$ . venv/bin/activate\n",
    "$ deactivate \n",
    "\n",
    "# Point the environment variable SPARK_HOME to your Spark installation\n",
    "$ export SPARK_HOME=\"/Users/lxu213/spark/\"\n",
    "\n",
    "# submit example job to spark\n",
    "$ $SPARK_HOME/bin/spark-submit ./server_count.py \\ --num_output_partitions 1 --log_level WARN \\ ./input/test_warc.txt servernames\n",
    "\n",
    "# readWARC: assuming that you have the aws command line tools installed, you can list the contents of a crawl using:\n",
    "$ aws s3 ls s3://commoncrawl/crawl-data/CC-MAIN-2014-10/ --recursive | head -6\n",
    "    \n",
    "# copy one segment to local using:\n",
    "$ aws s3 cp s3://commoncrawl/crawl-data/CC-MAIN-2014-10/segments/1394023864559/warc/CC-MAIN-20140305125104-00002-ip-10-183-142-35.ec2.internal.warc.gz ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Keywords Python Function\n",
    "\n",
    "Inherits from `CCSparkJob` and can run locally. # total number of records in warc.gz = 138,865"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract keywords\n",
    "kw_path = '/Users/lxu213/data/ad-free-search-engine/spark-warehouse/output_features/part-00000-34ccb7a1-4cbe-413d-bb91-165ea931b1f8-c000.snappy.parquet'\n",
    "data = pq.read_table(kw_path, nthreads=4).to_pandas()\n",
    "data['section'].unique()\n",
    "\n",
    "trips_wkd_rain = trips.loc[(trips['DoW'].isin([5,6])) & trips['PRCP'] != 0] \n",
    "data[['url', 'description']].loc[data['keywords'].isin(query.split(' '))] \n",
    "data[['url', 'description']].loc[data['keywords'].isin(['lily','cyrus'])] \n",
    "kw_data = data[['url', 'title', 'description']].loc[data['keywords'] == 'cities'][:10]\n",
    "data['url'].loc[data['keywords'] == 'cities']\n",
    "\n",
    "for index, row in data[:10].iterrows():\n",
    "    print row['keywords']\n",
    "    \n",
    "val = warc['val'] \n",
    "url = []\n",
    "for i in range(len(val)):\n",
    "    url.append(val[i]['url']) \n",
    "    \n",
    "data['description'].unique()\n",
    "# with adwords in links\n",
    "data.describe()\n",
    "# without adwords in links > removed about 25% of web pages\n",
    "data_adfree.describe()\n",
    "\n",
    "# Percent of crawled web pages that contain (detected) ad links:   # 26%\n",
    "100 - (100*data_adfree.count()['url']/data.count()['url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank by tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Process WARC\n",
    "PQPATH='/Users/lxu213/data/ad-free-search-engine/spark-warehouse/add_count/part-00000-6d70eeb9-5f8f-450b-ad70-f431c336e72d-c000.snappy.parquet'\n",
    "warc = pq.read_table(PQPATH, nthreads=4).to_pandas()\n",
    "# pq.ParquetFile(PQPATH).metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "warc['tf-idf'] = pd.Series(0, index=warc.index)\n",
    "tot_doc = len(warc)/10       # total documents\n",
    "\n",
    "for i in range(len(warc)):\n",
    "    docs_w_term = len(warc.loc[warc['keywords'] == warc['keywords'][i]])\n",
    "    warc.loc[i,'tf-idf'] = warc['val'][i]['count'] * np.log(tot_doc/docs_w_term)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pyarrow and fastparquet cannot handle nested dict in list\n",
    "warc = warc.rename(columns={'keywords': 'keywords', 'val': 'val', 'tf-idf': 'tf-idf'})\n",
    "type(warc.columns[0])\n",
    "warc.to_parquet(output_path, engine='fastparquet', compression='snappy')\n",
    "\n",
    "# check if kw_data[50] is dict not string\n",
    "PQPATH='/Users/lxu213/data/ad-free-search-engine/spark-warehouse/add_count/tf_idf.parquet'\n",
    "new = pq.read_table(PQPATH, nthreads=4).to_pandas()\n",
    "kw_data = new['val'].loc[new['keywords'].isin(['dog'])]\n",
    "type(kw_data[50])\n",
    "\n",
    "from fastparquet import write\n",
    "output_path = '/Users/lxu213/data/ad-free-search-engine/spark-warehouse/add_count/tf_idf.parquet'\n",
    "write(output_path, warc, file_scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'count': 10,\n",
       " u'description': u'None',\n",
       " u'title': u'Video - Cincinnati News, FOX19-WXIX TV',\n",
       " u'url': u'http://www.fox19.com/category/240225/video-landing-page?clipId=8475230&autostart=true'}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turns out json.loads can convert string to dict\n",
    "import json\n",
    "\n",
    "kw_dict = []\n",
    "for row in kw_data:\n",
    "    kw_dict.append(json.loads(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>val</th>\n",
       "      <th>tf-idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3862</th>\n",
       "      <td>dog</td>\n",
       "      <td>{\"url\": \"https://www.bestofdog.com/collections...</td>\n",
       "      <td>122.680971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>dog</td>\n",
       "      <td>{\"url\": \"http://www.fox19.com/category/240225/...</td>\n",
       "      <td>47.184989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>dog</td>\n",
       "      <td>{\"url\": \"http://almosthomeohio.org/in-memory/l...</td>\n",
       "      <td>33.029492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>dog</td>\n",
       "      <td>{\"url\": \"http://www.miragepetproducts.com/Brig...</td>\n",
       "      <td>14.155497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     keywords                                                val      tf-idf\n",
       "3862      dog  {\"url\": \"https://www.bestofdog.com/collections...  122.680971\n",
       "2122      dog  {\"url\": \"http://www.fox19.com/category/240225/...   47.184989\n",
       "50        dog  {\"url\": \"http://almosthomeohio.org/in-memory/l...   33.029492\n",
       "2698      dog  {\"url\": \"http://www.miragepetproducts.com/Brig...   14.155497"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.loc[new['keywords'] == 'dog'].sort_values('tf-idf', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "5       False\n",
       "6       False\n",
       "7       False\n",
       "8       False\n",
       "9       False\n",
       "10      False\n",
       "11      False\n",
       "12      False\n",
       "13      False\n",
       "14      False\n",
       "15      False\n",
       "16      False\n",
       "17      False\n",
       "18      False\n",
       "19      False\n",
       "20      False\n",
       "21      False\n",
       "22      False\n",
       "23      False\n",
       "24      False\n",
       "25      False\n",
       "26      False\n",
       "27      False\n",
       "28      False\n",
       "29      False\n",
       "        ...  \n",
       "4459    False\n",
       "4460    False\n",
       "4461    False\n",
       "4462    False\n",
       "4463    False\n",
       "4464    False\n",
       "4465    False\n",
       "4466    False\n",
       "4467    False\n",
       "4468    False\n",
       "4469    False\n",
       "4470    False\n",
       "4471    False\n",
       "4472    False\n",
       "4473    False\n",
       "4474    False\n",
       "4475    False\n",
       "4476    False\n",
       "4477    False\n",
       "4478    False\n",
       "4479    False\n",
       "4480    False\n",
       "4481    False\n",
       "4482    False\n",
       "4483    False\n",
       "4484    False\n",
       "4485    False\n",
       "4486    False\n",
       "4487    False\n",
       "4488    False\n",
       "Name: keywords, Length: 4489, dtype: bool"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PQPATH='/Users/lxu213/data/ad-free-search-engine/spark-warehouse/add_count/tf_idf.parquet'\n",
    "data = pq.read_table(PQPATH, nthreads=4).to_pandas()\n",
    "kw_data = data[['val', 'tf-idf']].loc[data['keywords'].isin(['dog'])]\n",
    "kw_data.sort_values('tf-idf', ascending=False)['val']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
